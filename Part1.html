<html>
<head>
</head>
<body>
	<h3>Neural Networks Explained</h3>
<pre>
	Artificial Intelligence
		- Reasoning as search
			- Heuristics
			- Combinatorial Explosion
			- The best vs the right answer
		- Structure

	Neurons
		- Biological neuron, basic parts
		- Electrical potentials added up
		- Two-unit networks model logic gates

	Multi-Layer Neural Networks
		- Equation is a linear combination
		- Logistic regression classification
		- Different kinds of activation functions
		- Networks as a change of base
		- Transforming inputs into linearly separable classes 
		- Why depth matters

	Features
		- Hand-crafting features
		- Unsupervised learning, autoencoders
		- Capturing features within an architecture: convolutional neural networks

</pre>

<!-- SECTION ONE -->
<h4>Artificial Intelligence</h4>
<pre>
[photo of alan turing] [photo of john von neumann]
	In 1936, Alan Turing (and, simultaneously, Alonzo Church) proved that any function which could be computed at all could be computed by any basic computer, given enough time-steps and memory. This implies that any physical system, subject to the laws of nature, can be simulated by a sufficiently powerful computer. And, barring dualism[footnote], this means that whatever our brains are doing a computer can theoretically replicate.
</pre>
	<h5>Reasoning as Search</h5>
<pre>
[Image of a Maze]
	Any AI problem can be framed as a search problem. Just like solving a maze (search through every combination of turns), proving a theorem (searching through the combinations of prepositions that can be deduced from given starting axioms), or playing chess (searching through tree of moves, followed by opposing moves, etc). This can even be applied to more abstract AI problems, such as signal processing: searching through a space of possible functions that best extracts the relevant information from some input signal.

	Early AI typically attacked this problem with a simple paradigm:
		- Proceeded step by step towards some goal
		- If stuck, go back a step and try something different

	This kind of approach is known as brute-force search. The problem, of course, is that it can be very slow. So to make things more efficient, sometimes a heuristic is added:
		- When presented with a set of possibilities, try the one that looks the most promising

[game tree image]
	But then there is another problem: that of combinatorial explosion. In chess, for example, there are an average of about 35 possible moves in any position, and an average game length of about 80 moves. So the number of positions one would have to examine in order to difinitively know the best opening move is about 35^80, or about 3.3 * 10^123. To put this in perspective, the number of atoms in the observable universe is estimated to be on the order of 10^80.

	So, given the size of the search space in chess, and the fact that, in order to be sure a move is the best, one has to eliminate all possibilities, a search heuristic is not enough. Here, a value function is required. Since it is, practically speaking, impossible to reach the bottom nodes of a chess search tree, one must find a way to weigh the value of positions before reaching the end, and use that value to guess what the best move in a given position will be.

	Unfortunately, this approach fails to solve the problem of finding the correct move given a position. The goal instead becomes finding the best move, given finite available resources.
</pre>
	<h5>Structure and Learning</h5>
<pre>
[image of a king-and-rook endgame]
	Suppose, however, that chess positions had a set of defineable properties. Suppose that there was a known algorithm for winning any position in which one player has a king and a rook, and the other player has only a king. In this case, all the possible positions with this structure become equivalent, for the purposes of winning the game. Now, given any chess position we could ask two yes-or-no questions (in chess, both players must always have kings):
	"Does one player have exactly a rook?"
	"Does the other player have no pieces left?"
	And if the answer to both questions is yes, then we can stop our search, and evaluate that node as winning for the player with the rook.

	By finding structure in a search space, it's possible to massively reduce the scale of a problem. And, really, this is the very purpose of science: by finding structure in our physical world, we are able to solve problems that are otherwise far too complex to fathom. And, in fact, the heuristics and value functions defined in the last section do the very same thing: they take advantage of the known structure of a problem space in order to search more efficiently (heuristic search), or to make a guess about some part of the search space (value function).

[image of a Go board] [image of a chess position] [stock trader image?] [maybe one more problem image]
	But, of course, the structure of one problem is seldom the same in another. And for many interesting problems, we don't know much of anything about their structure. This is where learning comes into play. By designing algorithms that learn about the structure of a problem, we take steps in the direction of true, generalized AI. This is what philosophers often refer to as "hard AI".

	And so, it seems natural to look to the one system we know of that's capable of finding structure in any arbitrary problem: the brain.
</pre>

<!-- Section two -->
<h4>Neurons</h4>
<pre>
[CLARITY brain image?]
	The human brain is composed of billions of electrically exciteable cells called neurons. These cells interact with one another in unfathomably complex networks via electrical and chemical signals. From this system emerges all that makes human beings so special: our capacity for abstract thought, our ability to communicate with one another, designs for machines that can bring us into outer space, the capacity to create art.
</pre>
<pre>
	Neurons are cells in the brain that perform an electrical function: they receive electrical signals via dendrites, and output electrical signals via axons. The connections between two neurons are called synapses. 
</body>
</html>